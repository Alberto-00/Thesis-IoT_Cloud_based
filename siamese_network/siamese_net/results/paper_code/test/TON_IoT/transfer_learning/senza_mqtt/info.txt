Preprocessing caricato da ../results/paper_code/train_test/senza_mqtt/preprocessing.pkl

Training Set Size: 88578
Validation Set Size: 22145
Test Set Size: 27681
Data are preprocessed!

Classes: 4
Total pairs generated: 1000000
Total duplicate attempts: 2773
Duplicates over total attempts: 2773/1000000

Classes: 4
Total pairs generated: 1000000
Total duplicate attempts: 2793
Duplicates over total attempts: 2793/1000000

Classes: 4
Total pairs generated: 50000
Total duplicate attempts: 6
Duplicates over total attempts: 6/50000

Pairs are generated!

Siamese Network Created:

Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input_1 (InputLayer)        [(None, 31, 1)]              0         []

 input_2 (InputLayer)        [(None, 31, 1)]              0         []

 sequential (Sequential)     (None, 32)                   453728    ['input_1[0][0]',
                                                                     'input_2[0][0]']

 lambda (Lambda)             (None, 1)                    0         ['sequential[0][0]',
                                                                     'sequential[1][0]']

==================================================================================================
Total params: 453728 (1.73 MB)
Trainable params: 453728 (1.73 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
Epoch 1/40
3907/3907 [==============================] - 268s 67ms/step - loss: 0.1043 - accuracy: 0.8614 - val_loss: 0.0950 - val_accuracy: 0.8763
Epoch 2/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0914 - accuracy: 0.8788 - val_loss: 0.0882 - val_accuracy: 0.8842
Epoch 3/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0828 - accuracy: 0.8892 - val_loss: 0.0762 - val_accuracy: 0.9007
Epoch 4/40
3907/3907 [==============================] - 328s 84ms/step - loss: 0.0742 - accuracy: 0.9020 - val_loss: 0.0715 - val_accuracy: 0.9049
Epoch 5/40
3907/3907 [==============================] - 251s 64ms/step - loss: 0.0709 - accuracy: 0.9058 - val_loss: 0.0694 - val_accuracy: 0.9061
Epoch 6/40
3907/3907 [==============================] - 254s 65ms/step - loss: 0.0694 - accuracy: 0.9075 - val_loss: 0.0703 - val_accuracy: 0.9045
Epoch 7/40
3907/3907 [==============================] - 256s 66ms/step - loss: 0.0680 - accuracy: 0.9093 - val_loss: 0.0666 - val_accuracy: 0.9101
Epoch 8/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0666 - accuracy: 0.9112 - val_loss: 0.0673 - val_accuracy: 0.9099
Epoch 9/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0653 - accuracy: 0.9134 - val_loss: 0.0645 - val_accuracy: 0.9144
Epoch 10/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0644 - accuracy: 0.9142 - val_loss: 0.0624 - val_accuracy: 0.9165
Epoch 11/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0632 - accuracy: 0.9154 - val_loss: 0.0632 - val_accuracy: 0.9126
Epoch 12/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0625 - accuracy: 0.9163 - val_loss: 0.0623 - val_accuracy: 0.9170
Epoch 13/40
3907/3907 [==============================] - 255s 65ms/step - loss: 0.0617 - accuracy: 0.9177 - val_loss: 0.0603 - val_accuracy: 0.9195
Epoch 14/40
3907/3907 [==============================] - 256s 65ms/step - loss: 0.0610 - accuracy: 0.9186 - val_loss: 0.0614 - val_accuracy: 0.9194
Epoch 15/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0605 - accuracy: 0.9190 - val_loss: 0.0606 - val_accuracy: 0.9184
Epoch 16/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0600 - accuracy: 0.9197 - val_loss: 0.0625 - val_accuracy: 0.9156
Epoch 17/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0596 - accuracy: 0.9198 - val_loss: 0.0596 - val_accuracy: 0.9200
Epoch 18/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0592 - accuracy: 0.9204 - val_loss: 0.0596 - val_accuracy: 0.9198
Epoch 19/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0588 - accuracy: 0.9210 - val_loss: 0.0588 - val_accuracy: 0.9211
Epoch 20/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0584 - accuracy: 0.9214 - val_loss: 0.0571 - val_accuracy: 0.9232
Epoch 21/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0581 - accuracy: 0.9217 - val_loss: 0.0566 - val_accuracy: 0.9235
Epoch 22/40
3907/3907 [==============================] - 261s 67ms/step - loss: 0.0578 - accuracy: 0.9222 - val_loss: 0.0566 - val_accuracy: 0.9234
Epoch 23/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0575 - accuracy: 0.9223 - val_loss: 0.0577 - val_accuracy: 0.9218
Epoch 24/40
3907/3907 [==============================] - 258s 66ms/step - loss: 0.0572 - accuracy: 0.9227 - val_loss: 0.0560 - val_accuracy: 0.9241
Epoch 25/40
3907/3907 [==============================] - 259s 66ms/step - loss: 0.0569 - accuracy: 0.9233 - val_loss: 0.0554 - val_accuracy: 0.9256
Epoch 26/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0566 - accuracy: 0.9237 - val_loss: 0.0553 - val_accuracy: 0.9254
Epoch 27/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0565 - accuracy: 0.9238 - val_loss: 0.0555 - val_accuracy: 0.9256
Epoch 28/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0561 - accuracy: 0.9241 - val_loss: 0.0569 - val_accuracy: 0.9237
Epoch 29/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0558 - accuracy: 0.9245 - val_loss: 0.0564 - val_accuracy: 0.9234
Epoch 30/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0556 - accuracy: 0.9248 - val_loss: 0.0557 - val_accuracy: 0.9248
Epoch 31/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0553 - accuracy: 0.9252 - val_loss: 0.0544 - val_accuracy: 0.9270
Epoch 32/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0550 - accuracy: 0.9256 - val_loss: 0.0550 - val_accuracy: 0.9255
Epoch 33/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0548 - accuracy: 0.9261 - val_loss: 0.0539 - val_accuracy: 0.9261
Epoch 34/40
3907/3907 [==============================] - 256s 65ms/step - loss: 0.0544 - accuracy: 0.9263 - val_loss: 0.0537 - val_accuracy: 0.9265
Epoch 35/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0541 - accuracy: 0.9267 - val_loss: 0.0535 - val_accuracy: 0.9289
Epoch 36/40
3907/3907 [==============================] - 256s 65ms/step - loss: 0.0539 - accuracy: 0.9271 - val_loss: 0.0535 - val_accuracy: 0.9277
Epoch 37/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0536 - accuracy: 0.9276 - val_loss: 0.0536 - val_accuracy: 0.9276
Epoch 38/40
3907/3907 [==============================] - 256s 66ms/step - loss: 0.0534 - accuracy: 0.9280 - val_loss: 0.0527 - val_accuracy: 0.9286
Epoch 39/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0533 - accuracy: 0.9280 - val_loss: 0.0593 - val_accuracy: 0.9209
Epoch 40/40
3907/3907 [==============================] - 257s 66ms/step - loss: 0.0530 - accuracy: 0.9285 - val_loss: 0.0543 - val_accuracy: 0.9255

Modello salvato in ../results/paper_code/test/TON_IoT/transfer_learning/senza_mqtt/
Pre-processing salvato!

1563/1563 [==============================] - 7s 4ms/step - loss: 0.0611 - accuracy: 0.9160
Test Loss: 0.0611, Test Accuracy: 0.9160
1563/1563 [==============================] - 5s 3ms/step
              precision    recall  f1-score   support

           0       0.89      0.95      0.92     25000
           1       0.95      0.88      0.91     25000

    accuracy                           0.92     50000
   macro avg       0.92      0.92      0.92     50000
weighted avg       0.92      0.92      0.92     50000